{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Tgm8mCA9Dp3"
   },
   "source": [
    "# Laboratorio 5: Clasificaci√≥n ü§ó\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2024</strong></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11Kc_ibM9GXH"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesores: Stefano Schiappacasse, Sebasti√°n Tinoco\n",
    "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
    "- Ayudantes: Angelo Mu√±oz, Valentina Z√∫√±iga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9dUSltr9JrN"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
    "\n",
    "- Nombre de alumno 1: *Diego Espinoza N√∫√±ez*\n",
    "- Nombre de alumno 2: *Juan Mi√±o*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC1IloytrsAx"
   },
   "source": [
    "### **Link de repositorio de GitHub:** [juansebm/MDS7202](https://github.com/juansebm/MDS7202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBa48PDF9OHw"
   },
   "source": [
    "### Temas a tratar\n",
    "- Clasificaci√≥n en problemas desbalanceados\n",
    "- Lightgbm y xgboost\n",
    "- Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkhnnMx49Qrh"
   },
   "source": [
    "## Reglas:\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Fecha de entrega: 6 d√≠as de plazo con descuento de 1 punto por d√≠a. Entregas Martes a las 23:59.\n",
    "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
    "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
    "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
    "- Pueden usar cualquier material del curso que estimen conveniente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxzJ48Vv8quO"
   },
   "source": [
    "\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "- Comprender c√≥mo trabajar con problemas de clasificaci√≥n con clases desbalanceadas.\n",
    "- Aplicar los modelos lightgbm y xgboost.\n",
    "- Practicar Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-ao0mOU64Ru"
   },
   "source": [
    "# Parte Te√≥rica [12 puntos]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApXKwPDmxcEV"
   },
   "source": [
    "1. Explique cu√°l es la diferencia entre los datos de entrenamiento y validaci√≥n. [1 punto]\n",
    "\n",
    "2. Explique cu√°l es el principal desaf√≠o al trabajar problemas de clasificaci√≥n con data no supervisada. [1 punto]\n",
    "\n",
    "3. Explique en **sus palabras** qu√© es la matriz de confusi√≥n y para qu√© se utiliza. [1 puntos]\n",
    "\n",
    "4. Escriba la f√≥rmula de las siguientes m√©tricas y explique con **sus palabras** c√≥mo se interpretan. [1 punto cada uno]\n",
    "\n",
    "  * Accuracy\n",
    "  * Precision\n",
    "  * Recall\n",
    "  * F1 score\n",
    "\n",
    "5. Explique qu√© m√©trica recomendar√≠a para los siguientes contextos de clasificaci√≥n. [1 punto cada uno]\n",
    "\n",
    "  * Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \n",
    "  * Detecci√≥n de enfermedades altamente contagiosas.\n",
    "  * Aprobaci√≥n de cr√©ditos de alto riesgo.\n",
    "  * Detecci√≥n de cr√≠menes.\n",
    "\n",
    "6. Explique qu√© es la calibraci√≥n de modelos y para qu√© se usa. [1 punto]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy4QMWD8-FPk"
   },
   "source": [
    "**Respuesta:**\n",
    "\n",
    "1. **Entrenamiento se usa para entrenar el modelo. Validaci√≥n se utiliza para seleccionar el mejor modelo a medida que se alteran los hiperpar√°metros.**\n",
    "2.\n",
    "3.\n",
    "4.\n",
    "5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYFdD1aK-ICa"
   },
   "source": [
    "*Escriba su respuesta aqu√≠*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg_9jBqtgRDO"
   },
   "source": [
    "# Parte pr√°ctica [48 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slm6yRfdfZwS"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1BnO4tyh3vM2P199Ec9s3JjngQ4qQ9seP\"\n",
    "\" width=\"300\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Tras el tr√°gico despido de la m√≠tica mascota de Maip√∫, Renac√≠n decide adentrarse como consultor en el mercado futbolero, el cu√°l (para variar...) est√° cargado en especulaciones.\n",
    "\n",
    "Como su principal tarea ser√° asesorar a los directivos de los clubes sobre cu√°l jugador comprar y cu√°l no, Renac√≠n desea generar modelos predictivos que evalu√©n distintas caracter√≠sticas de los jugadores; todo con el fin de tomar decisiones concretas basadas en los datos.\n",
    "\n",
    "Sin embargo, su condici√≥n de corporeo le impidi√≥ tomar la versi√≥n anterior de MDS7202, por lo que este motivo Renac√≠n contrata a su equipo para lograr su objetivo final. Dado que a√∫n tiene fuertes v√≠nculos con la direcci√≥n de deportes de la municipalidad, el corporeo le entrega base de datos con las estad√≠sticas de cada jugador para que su equipo empieze a trabajar ya con un dataset listo para ser usado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnbx7RwHfkue"
   },
   "source": [
    "**Los Datos**\n",
    "\n",
    "Para este laboratorio deber√°n trabajar con el csv `statsplayers.csv`, donde deber√°n aplicar algoritmos de aprendizaje supervisado de clasificaci√≥n en base a caracter√≠sticas que describen de jugadores de f√∫tbol.\n",
    "\n",
    "Para comenzar cargue el dataset se√±alado y a continuaci√≥n vea el reporte **`Player_Stats_Report.html`** (adjunto en la carpeta del enunciado) que describe las caracter√≠sticas principales del `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mX6iwOWUfrp_"
   },
   "outputs": [],
   "source": [
    "# Si usted est√° utilizando Colabolatory le puede ser √∫til este c√≥digo para cargar los archivos.\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    path = 'Direcci√≥n donde tiene los archivos en el Drive'\n",
    "except:\n",
    "    print('Ignorando conexi√≥n drive-colab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdcucZhp-M_0"
   },
   "source": [
    "## 1. Predicci√≥n de Seleccionados Nacionales [14 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXrewqxjjzvA"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://www.futuro.cl/wp-content/uploads/2016/06/chile-argentina-meme-12.jpg\" width=\"300\">\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qfre1YsSDqla"
   },
   "source": [
    "### 1.1 Preprocesamiento [5 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR00u4HTDtxv"
   },
   "source": [
    "Tareas:\n",
    "\n",
    "1. Genere los labels para la clasificaci√≥n binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su pa√≠s. [Sin puntaje]\n",
    "\n",
    "2. Hecho esto, ¬øcu√°ntos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]\n",
    "\n",
    "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y gu√°rdelo una variable llamada `col_transformer`. [2 puntos]\n",
    "\n",
    "4. Comente y justifique las transformaciones elegidas sobre cada una de las variables (para esto utilice el material `Player_Stats_Report.html` que viene en el zip del lab), al igual que las transformaciones aplicadas. [2 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgAk0kbPjEsx"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhC2sZj9dSI1"
   },
   "outputs": [],
   "source": [
    "# 1. Cargar y preparar los datos\n",
    "df = pd.read_csv('statsplayers.csv')\n",
    "\n",
    "# Definir grupos de posiciones (excluyendo arquero)\n",
    "position_groups = {\n",
    "    'ataque': ['ST', 'CF'],\n",
    "    'central_ataque': ['RW', 'CAM', 'LW'],\n",
    "    'central': ['RM', 'CM', 'LM'],\n",
    "    'central_defensa': ['RWB', 'CDM', 'LWB'],\n",
    "    'defensa': ['RB', 'CB', 'LB']\n",
    "}\n",
    "\n",
    "# Filtrar posiciones v√°lidas\n",
    "valid_positions = [pos for group in position_groups.values() for pos in group]\n",
    "df_filtered = df[df['Club_Position'].isin(valid_positions)].copy()\n",
    "\n",
    "# Crear labels\n",
    "df_filtered['label'] = df_filtered['Club_Position'].apply(\n",
    "    lambda x: next((k for k, v in position_groups.items() if x in v), None)\n",
    ")\n",
    "df_filtered = df_filtered.dropna(subset=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bv1HOfcNEPF4"
   },
   "source": [
    "### 1.2 Entrenamiento [3 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPkuXTUBvB0"
   },
   "source": [
    "Ahora, vamos a entrenar los pipelines generados en los pasos anteriores. Para esto, debe realizar las siguientes tareas:\n",
    "\n",
    "1. Separe los datos de entrenamiento en un conjunto de entrenamiento y de prueba  (la proporci√≥n queda a su juicio). En este paso, seleccione los ejemplos de forma aleatoria e intente mantener la distribuci√≥n original de labels de cada clase en los conjuntos de prueba/entrenamiento. (vea la documentaci√≥n de `train_test_split`). [1 puntos]\n",
    "\n",
    "\n",
    "2. Defina un pipeline llamado `pipeline_xgboost` y otro llamado `pipeline_lightgbm`. Estos pipelines deben tener el mismo ColumnTransformer definido en la secci√≥n de preprocesamiento, pero deben variar los clasificadores de acuerdo al nombre de cada pipeline. [1 puntos]\n",
    "\n",
    "3. Entrene los pipelines. [1 punto]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbadONFtjGnE"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLtlXGTPdWAV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poc9HSNBFeKO"
   },
   "source": [
    "### 1.3 Resultados [6 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGGCj8YtFil1"
   },
   "source": [
    "1. Calcule las m√©tricas accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
    "\n",
    "2. Explique qu√© implican los valores de accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y c√≥mo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
    "\n",
    "3. Explique qu√© m√©trica le parece m√°s adecuada y concluya qu√© modelo tiene un mejor desempe√±o. [2 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1hkVFdujJTi"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNmI_tbbdQte"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy5VMU6ae_g6"
   },
   "source": [
    "## 2. Predicci√≥n de posiciones de jugadores [4 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0PGg_hLgr4H"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://pbs.twimg.com/media/E1rfA1aWEAYU6Ny.jpg\" width=\"300\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6rSnAesfOm3"
   },
   "source": [
    "En una nueva jornada de desmesuradas transacciones deportivas, Renac√≠n escuch√≥ a sus colegas discutir acerca de que el precio de cada jugador depende en gran medida de la posici√≥n en la cancha en la que juega. Y adem√°s, que hay bastantes jugadores nuevos que no tienen muy claro en que posici√≥n verdaderamente brillar√≠an, por lo que actualmente puede que actualmente est√©n jugando en posiciones sub-optimas.\n",
    "\n",
    "Viendo que los resultados del primer an√°lisis no son tan esperanzadores, el corporeo los comanda a cambiar su tarea: ahora, les solicita que construyan un clasificador enfocado en predecir la mejor posici√≥n de los jugadores en la cancha seg√∫n sus caracter√≠sticas.\n",
    "\n",
    "Para lograr esto, primero, les pide que etiqueten de la siguiente manera los valores que aparecen en el atributo `Club_Position`, pidiendo que agrupen los valores en los siguientes grupos:\n",
    "\n",
    "**Nota**:  Renac√≠n les recalca que **no deben utilizar los valores ```Sub``` y ```Res``` de esta columna**.\n",
    "\n",
    "```python\n",
    "ataque = ['ST', 'CF']\n",
    "central_ataque = ['RW', 'CAM', 'LW']\n",
    "central = ['RM', 'CM', 'LM']\n",
    "central_defensa = ['RWB', 'CDM', 'LWB']\n",
    "defensa = ['RB', 'CB', 'LB']\n",
    "arquero = ['GK']\n",
    "```\n",
    "\n",
    "La elecci√≥n del clasificador se justificar en base a la siguiente [gu√≠a](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) y se deben comentar los resultados obtenidos en la clasificaci√≥n.\n",
    "\n",
    "**Tareas:** [1 punto por tarea]\n",
    "\n",
    "1. En un nuevo dataframe, aplique las etiquetas descritas anteriormente en cada uno de los valores se√±alados en esta secci√≥n y gu√°rdelos en la variable `label`.\n",
    "2. Cuente cu√°ntos por clase quedan.\n",
    "3. Entrene el nuevo pipeline y ejecute una evaluaci√≥n de este.  \n",
    "4. Comente los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBmSaWh8i2MI"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ir_7zMh2i1vg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bL2m8nNojXM"
   },
   "source": [
    "## 3. Predicciones de Seleccionados Nacionales para el Jere Klein [30 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2XmRsJdsEh_"
   },
   "source": [
    "<center>\n",
    "<img src='https://www.radioactiva.cl/wp-content/uploads/2024/04/Jere-Klein-1-768x432.webp' width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgmUoVDsqUPu"
   },
   "source": [
    "Despu√©s de alcanzar la fama como cantante urbano, Jere Klein decide explorar una nueva faceta. Con su amor por el f√∫tbol y convencido de que los artistas urbanos poseen un talento y versatilidad excepcionales, Jere se embarca en un proyecto innovador: desarrollar un sistema de inteligencia artificial capaz de identificar a jugadores que tienen potencial para convertirse en futbolistas profesionales. Su teor√≠a es que muchos artistas del g√©nero urbano chileno, con sus habilidades √∫nicas y su disciplina, podr√≠an destacarse tambi√©n en el deporte. Con este sistema, Jere espera no solo abrir nuevas oportunidades para sus colegas artistas, sino tambi√©n demostrar la amplia gama de talentos que pueden ofrecer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD8pQ5Zfq8dE"
   },
   "source": [
    "### 2.1 ¬øQu√© modelo de √°rbol es m√°s de \"pana\"? [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zB-KUA4g99eo"
   },
   "source": [
    "<center>\n",
    "<img src='https://64.media.tumblr.com/39189215a7d3d96823cb359f35b44e05/tumblr_psmrhrR3Xw1qf5hjqo4_540.gif' width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uL-moVhB9vPH"
   },
   "source": [
    "\n",
    "**Tareas**\n",
    "\n",
    "\n",
    "1. Considerando el la variable llamada `label` creada en la secci√≥n 1.1. Para determinar cu√°l modelo de √°rbol ser√≠a m√°s adecuado para la tarea en cuesti√≥n, utilice PyCaret. Este deber√° centrarse exclusivamente en modelos de tipo √°rbol. Jere ha especificado que busca un modelo que tome decisiones r√°pidamente y que tenga una baja tasa de falsos positivos, ya que planea invertir en estos jugadores. [3 puntos]\n",
    "\n",
    "Para la comparaci√≥n, utilice los siguientes modelos:\n",
    "\n",
    "```python\n",
    "['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
    "```\n",
    "\n",
    "2. Explique en brevemente que son los modelos de la siguiente lista `['et', 'rf', 'dt']` y como funcionan. [3 punto]\n",
    "\n",
    "3. Tras realizar la comparaci√≥n de modelos, seleccione aquel que muestre el mejor rendimiento en t√©rminos de velocidad y precisi√≥n, especialmente en la reducci√≥n de falsos positivos. Utilice la funci√≥n `evaluate_model` de PyCaret para revisar y analizar los resultados obtenidos en los siguientes aspectos:\n",
    "\n",
    "  - **Confusi√≥n Matrix**: ¬øC√≥mo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
    "  - **Threshold**: ¬øEs acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
    "  - **Feature Importance**: ¬øCu√°les son las variables con mejor desempe√±o? ¬øA qu√© podr√≠a deberse esto?\n",
    "  - **Learning Curve**: ¬øEl modelo presenta alg√∫n problema?\n",
    "\n",
    "  [4 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qY85nrViYROF"
   },
   "source": [
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Cargar y preparar datos (basado en tu c√≥digo)\n",
    "df = pd.read_csv('stats_players.csv')\n",
    "\n",
    "# Definir grupos de posiciones\n",
    "position_groups = {\n",
    "    'ataque': ['ST', 'CF'],\n",
    "    'central_ataque': ['RW', 'CAM', 'LW'],\n",
    "    'central': ['RM', 'CM', 'LM'],\n",
    "    'central_defensa': ['RWB', 'CDM', 'LWB'],\n",
    "    'defensa': ['RB', 'CB', 'LB']\n",
    "}\n",
    "\n",
    "# Filtrar posiciones v√°lidas\n",
    "valid_positions = [pos for group in position_groups.values() for pos in group]\n",
    "df = df[df['Club_Position'].isin(valid_positions)].copy()\n",
    "\n",
    "# Crear variable label\n",
    "df['label'] = df['Club_Position'].apply(\n",
    "    lambda x: next((k for k, v in position_groups.items() if x in v), None)\n",
    ")\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# Preparar datos para PyCaret\n",
    "data = df.drop('Club_Position', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUCjOjsEYUXL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ad764 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ad764_row0_col0, #T_ad764_row0_col4, #T_ad764_row1_col0, #T_ad764_row1_col1, #T_ad764_row1_col2, #T_ad764_row1_col3, #T_ad764_row1_col5, #T_ad764_row1_col6, #T_ad764_row1_col7, #T_ad764_row2_col0, #T_ad764_row2_col1, #T_ad764_row2_col2, #T_ad764_row2_col3, #T_ad764_row2_col4, #T_ad764_row2_col5, #T_ad764_row2_col6, #T_ad764_row2_col7, #T_ad764_row3_col0, #T_ad764_row3_col1, #T_ad764_row3_col2, #T_ad764_row3_col3, #T_ad764_row3_col4, #T_ad764_row3_col5, #T_ad764_row3_col6, #T_ad764_row3_col7, #T_ad764_row4_col0, #T_ad764_row4_col1, #T_ad764_row4_col2, #T_ad764_row4_col3, #T_ad764_row4_col4, #T_ad764_row4_col5, #T_ad764_row4_col6, #T_ad764_row4_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ad764_row0_col1, #T_ad764_row0_col2, #T_ad764_row0_col3, #T_ad764_row0_col5, #T_ad764_row0_col6, #T_ad764_row0_col7, #T_ad764_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_ad764_row0_col8, #T_ad764_row1_col8, #T_ad764_row2_col8, #T_ad764_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_ad764_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ad764\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ad764_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_ad764_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_ad764_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_ad764_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_ad764_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_ad764_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_ad764_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_ad764_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_ad764_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ad764_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_ad764_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_ad764_row0_col1\" class=\"data row0 col1\" >0.3232</td>\n",
       "      <td id=\"T_ad764_row0_col2\" class=\"data row0 col2\" >0.8251</td>\n",
       "      <td id=\"T_ad764_row0_col3\" class=\"data row0 col3\" >0.3232</td>\n",
       "      <td id=\"T_ad764_row0_col4\" class=\"data row0 col4\" >0.4799</td>\n",
       "      <td id=\"T_ad764_row0_col5\" class=\"data row0 col5\" >0.2659</td>\n",
       "      <td id=\"T_ad764_row0_col6\" class=\"data row0 col6\" >0.1745</td>\n",
       "      <td id=\"T_ad764_row0_col7\" class=\"data row0 col7\" >0.2249</td>\n",
       "      <td id=\"T_ad764_row0_col8\" class=\"data row0 col8\" >1.3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad764_level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n",
       "      <td id=\"T_ad764_row1_col0\" class=\"data row1 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_ad764_row1_col1\" class=\"data row1 col1\" >0.2433</td>\n",
       "      <td id=\"T_ad764_row1_col2\" class=\"data row1 col2\" >0.7545</td>\n",
       "      <td id=\"T_ad764_row1_col3\" class=\"data row1 col3\" >0.2433</td>\n",
       "      <td id=\"T_ad764_row1_col4\" class=\"data row1 col4\" >0.5051</td>\n",
       "      <td id=\"T_ad764_row1_col5\" class=\"data row1 col5\" >0.1422</td>\n",
       "      <td id=\"T_ad764_row1_col6\" class=\"data row1 col6\" >0.1166</td>\n",
       "      <td id=\"T_ad764_row1_col7\" class=\"data row1 col7\" >0.1580</td>\n",
       "      <td id=\"T_ad764_row1_col8\" class=\"data row1 col8\" >0.7240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad764_level0_row2\" class=\"row_heading level0 row2\" >dt</th>\n",
       "      <td id=\"T_ad764_row2_col0\" class=\"data row2 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_ad764_row2_col1\" class=\"data row2 col1\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row2_col2\" class=\"data row2 col2\" >0.5005</td>\n",
       "      <td id=\"T_ad764_row2_col3\" class=\"data row2 col3\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row2_col4\" class=\"data row2 col4\" >0.1746</td>\n",
       "      <td id=\"T_ad764_row2_col5\" class=\"data row2 col5\" >0.0544</td>\n",
       "      <td id=\"T_ad764_row2_col6\" class=\"data row2 col6\" >0.0009</td>\n",
       "      <td id=\"T_ad764_row2_col7\" class=\"data row2 col7\" >0.0125</td>\n",
       "      <td id=\"T_ad764_row2_col8\" class=\"data row2 col8\" >0.8840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad764_level0_row3\" class=\"row_heading level0 row3\" >xgboost</th>\n",
       "      <td id=\"T_ad764_row3_col0\" class=\"data row3 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_ad764_row3_col1\" class=\"data row3 col1\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row3_col2\" class=\"data row3 col2\" >0.7172</td>\n",
       "      <td id=\"T_ad764_row3_col3\" class=\"data row3 col3\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row3_col4\" class=\"data row3 col4\" >0.1746</td>\n",
       "      <td id=\"T_ad764_row3_col5\" class=\"data row3 col5\" >0.0544</td>\n",
       "      <td id=\"T_ad764_row3_col6\" class=\"data row3 col6\" >0.0009</td>\n",
       "      <td id=\"T_ad764_row3_col7\" class=\"data row3 col7\" >0.0125</td>\n",
       "      <td id=\"T_ad764_row3_col8\" class=\"data row3 col8\" >0.9440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad764_level0_row4\" class=\"row_heading level0 row4\" >lightgbm</th>\n",
       "      <td id=\"T_ad764_row4_col0\" class=\"data row4 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_ad764_row4_col1\" class=\"data row4 col1\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row4_col2\" class=\"data row4 col2\" >0.6665</td>\n",
       "      <td id=\"T_ad764_row4_col3\" class=\"data row4 col3\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row4_col4\" class=\"data row4 col4\" >0.1746</td>\n",
       "      <td id=\"T_ad764_row4_col5\" class=\"data row4 col5\" >0.0544</td>\n",
       "      <td id=\"T_ad764_row4_col6\" class=\"data row4 col6\" >0.0009</td>\n",
       "      <td id=\"T_ad764_row4_col7\" class=\"data row4 col7\" >0.0125</td>\n",
       "      <td id=\"T_ad764_row4_col8\" class=\"data row4 col8\" >0.4640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2409246ec10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.datasets import get_data\n",
    "from pycaret.classification import *\n",
    "import os\n",
    "\n",
    "os.environ[\"PYCARET_CUSTOM_LOGGING_LEVEL\"] = \"CRITICAL\"\n",
    "\n",
    "\n",
    "# Configurar el entorno de PyCaret\n",
    "clf = setup(\n",
    "    data=data,  # ‚úÖ Aqu√≠ est√°s usando el df limpio sin Club_Position\n",
    "    target='label',\n",
    "    session_id=123, \n",
    "    fold_strategy='kfold',\n",
    "    fold=5,\n",
    "    verbose=False, \n",
    "    use_gpu=False,  # ‚ö†Ô∏è pon False si no est√°s en Colab con GPU de NVIDIA\n",
    "    log_experiment=False\n",
    ")\n",
    "\n",
    "# Modelos a comparar (solo modelos de √°rboles)\n",
    "modelos_arbol = ['et', 'rf', 'dt', 'xgboost', 'lightgbm'] # catboost NO DISPONIBLE!\n",
    "\n",
    "# Comparar modelos\n",
    "best_model = compare_models(include=modelos_arbol, sort='F1')  # Buscamos balance entre precision y recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3307, 40)\n",
      "label\n",
      "defensa            1180\n",
      "central             907\n",
      "central_ataque      581\n",
      "ataque              430\n",
      "central_defensa     209\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_filtered.shape)\n",
    "print(df_filtered['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decision Tree (√Årbol de Decisi√≥n):*\n",
    "Es un modelo que clasifica datos dividi√©ndolos de forma jer√°rquica mediante condiciones como \"¬øX > umbral?\". Utiliza m√©tricas como Gini o Entrop√≠a para elegir las divisiones. Es f√°cil de interpretar, pero puede sobreajustarse si no se limita su profundidad.\n",
    "\n",
    "*Random Forest:*\n",
    "Consiste en m√∫ltiples √°rboles de decisi√≥n entrenados sobre subconjuntos aleatorios de los datos y caracter√≠sticas. Combina sus predicciones por votaci√≥n mayoritaria, lo que reduce el sobreajuste y mejora la precisi√≥n.\n",
    "\n",
    "*Extra Trees:*\n",
    "Es similar a Random Forest, pero introduce a√∫n m√°s aleatoriedad al seleccionar divisiones de forma aleatoria en vez de √≥ptima. Esto permite entrenamientos m√°s r√°pidos y, en algunos casos, mejor generalizaci√≥n, aunque con posible p√©rdida leve de precisi√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*El mejor modelo fue Extra Trees Classifier, ya que obtuvo los valores m√°s altos en todas las m√©tricas clave: Accuracy (0.3232), AUC (0.8251), Recall (0.3232), y especialmente F1 Score (0.2659), lo que indica un buen balance entre precisi√≥n y sensibilidad. Adem√°s, su MCC de 0.2249 y Kappa de 0.1745 superan ampliamente al resto, lo que confirma que logra una mejor discriminaci√≥n entre clases. Aunque su tiempo de entrenamiento fue m√°s alto, el desempe√±o global justifica su elecci√≥n como el modelo m√°s robusto para esta tarea.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8DSS3u1xMpB"
   },
   "source": [
    "### 2.2 Reducci√≥n de dimensionalidad [14 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLu0543p876P"
   },
   "source": [
    "<center>\n",
    "<img src='https://i.kym-cdn.com/photos/images/original/002/258/560/668.gif' width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT-bxJ0txwNF"
   },
   "source": [
    "A pesar de los resultados obtenidos previamente, el manager de Jere ha solicitado el entrenamiento de un modelo de XGBoost utilizando los datos disponibles. Adem√°s, se debe proceder a realizar una reducci√≥n de dimensionalidad basada en la importancia de las caracter√≠sticas.\n",
    "\n",
    "Para llevar a cabo esta tarea:\n",
    "\n",
    "1. Inicie entrenando un modelo XGBoost con todas las caracter√≠sticas disponibles. [2 puntos]\n",
    "\n",
    "2. Una vez el modelo est√© entrenado, eval√∫e y clasifique las caracter√≠sticas seg√∫n su importancia de forma descendente. [2 puntos]\n",
    "\n",
    "3. Utilice esta clasificaci√≥n para ejecutar una b√∫squeda recursiva de eliminaci√≥n de caracter√≠sticas, eliminando progresivamente las menos importantes y evaluando el impacto en el desempe√±o del modelo hasta identificar las N caracter√≠sticas m√°s cr√≠ticas. [2 puntos]\n",
    "\n",
    "4. Con este conjunto reducido de caracter√≠sticas, entrene un nuevo modelo y eval√∫e su rendimiento. [2 puntos]\n",
    "\n",
    "5. Posteriormente, responda a las siguientes preguntas para una comprensi√≥n m√°s profunda de los cambios y beneficios:\n",
    "\n",
    "  - ¬øEl rendimiento del modelo con las caracter√≠sticas seleccionadas es similar al del modelo original? ¬øC√≥mo se comparan en t√©rminos de precisi√≥n y robustez? [2 puntos]\n",
    "  - ¬øCu√°les son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificaci√≥n del modelo, reducci√≥n del tiempo de entrenamiento, y mejora en la capacidad de generalizaci√≥n. [2 puntos]\n",
    "  - Comente si el modelo con menor dimensionalidad es m√°s sencillo de explicar. Explique brevemente por qu√© la eliminaci√≥n de ciertas caracter√≠sticas puede facilitar la comprensi√≥n y la explicaci√≥n del comportamiento del modelo. [2 puntos]\n",
    "\n",
    "Notar que con esta metodologia buscamos encontrar un punto entermedio entre n√∫mero de festures y desempe√±o. por esto, si observa que al aumentar festires el aumento es despreciable, puede no considerar agregar m√°s features a su modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHfmK63TuDOS"
   },
   "source": [
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "HQwUd_nsuDOe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo original:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86        86\n",
      "           1       0.58      0.64      0.61       182\n",
      "           2       0.48      0.38      0.42       116\n",
      "           3       0.63      0.29      0.39        42\n",
      "           4       0.85      0.94      0.89       236\n",
      "\n",
      "    accuracy                           0.71       662\n",
      "   macro avg       0.67      0.62      0.63       662\n",
      "weighted avg       0.69      0.71      0.70       662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"stats_players.csv\")\n",
    "\n",
    "# Definir grupos de posiciones\n",
    "position_groups = {\n",
    "    'ataque': ['ST', 'CF'],\n",
    "    'central_ataque': ['RW', 'CAM', 'LW'],\n",
    "    'central': ['RM', 'CM', 'LM'],\n",
    "    'central_defensa': ['RWB', 'CDM', 'LWB'],\n",
    "    'defensa': ['RB', 'CB', 'LB']\n",
    "}\n",
    "\n",
    "# Filtrar solo posiciones v√°lidas\n",
    "valid_positions = [pos for v in position_groups.values() for pos in v]\n",
    "df = df[df['Club_Position'].isin(valid_positions)].copy()\n",
    "\n",
    "# Crear etiquetas\n",
    "df['label'] = df['Club_Position'].apply(lambda x: next(k for k, v in position_groups.items() if x in v))\n",
    "\n",
    "# Codificar etiquetas a n√∫meros\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['label'])\n",
    "\n",
    "# Eliminar columnas irrelevantes de texto\n",
    "drop_cols = ['Club_Position', 'label', 'Name', 'Nationality', 'National_Position', 'Preffered_Foot', 'Work_Rate', 'Body_Type', 'Real_Face', 'Position', 'Joined', 'Loaned_From', 'Contract_Valid_Until', 'Best_Position']\n",
    "X = df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Convertir posibles columnas categ√≥ricas restantes en num√©ricas (si queda alguna)\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# Split en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo\n",
    "model_full = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "model_full.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar desempe√±o\n",
    "y_pred_full = model_full.predict(X_test)\n",
    "print(\"Modelo original:\\n\", classification_report(y_test, y_pred_full))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            feature  importance\n",
      "8    Sliding_Tackle    0.224784\n",
      "27        Finishing    0.060838\n",
      "7           Marking    0.059455\n",
      "25          Heading    0.047663\n",
      "15         Crossing    0.045030\n",
      "13           Vision    0.043964\n",
      "9   Standing_Tackle    0.030099\n",
      "16       Short_Pass    0.027484\n",
      "17        Long_Pass    0.026890\n",
      "19            Speed    0.026389\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model_full.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(feature_importance.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 features ‚Üí F1 Score: 0.6223\n",
      "10 features ‚Üí F1 Score: 0.6984\n",
      "15 features ‚Üí F1 Score: 0.6829\n",
      "20 features ‚Üí F1 Score: 0.6997\n",
      "25 features ‚Üí F1 Score: 0.6684\n",
      "30 features ‚Üí F1 Score: 0.6857\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for n in range(5, len(feature_importance)+1, 5):\n",
    "    top_features = feature_importance['feature'].iloc[:n].tolist()\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "    model.fit(X_train[top_features], y_train)\n",
    "    preds = model.predict(X_test[top_features])\n",
    "    score = f1_score(y_test, preds, average='weighted')\n",
    "    scores.append((n, score))\n",
    "\n",
    "# Mostrar resultados\n",
    "for n, score in scores:\n",
    "    print(f\"{n} features ‚Üí F1 Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo reducido:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        86\n",
      "           1       0.61      0.64      0.63       182\n",
      "           2       0.47      0.40      0.43       116\n",
      "           3       0.71      0.24      0.36        42\n",
      "           4       0.84      0.95      0.89       236\n",
      "\n",
      "    accuracy                           0.72       662\n",
      "   macro avg       0.69      0.63      0.63       662\n",
      "weighted avg       0.70      0.72      0.70       662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n = 20\n",
    "selected_features = feature_importance['feature'].iloc[:top_n].tolist()\n",
    "\n",
    "model_reduced = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "model_reduced.fit(X_train[selected_features], y_train)\n",
    "\n",
    "y_pred_reduced = model_reduced.predict(X_test[selected_features])\n",
    "print(\"Modelo reducido:\\n\", classification_report(y_test, y_pred_reduced))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¬øEl rendimiento del modelo con las caracter√≠sticas seleccionadas es similar al del modelo original?\n",
    "\n",
    "S√≠, el rendimiento del modelo reducido fue comparable al modelo original. La m√©trica F1 Score se mantuvo estable con solo 20 caracter√≠sticas, lo que sugiere que las variables eliminadas aportaban poca informaci√≥n adicional. La precisi√≥n y robustez del modelo se mantuvieron sin comprometer su capacidad predictiva.\n",
    "\n",
    "- ¬øCu√°les son los beneficios potenciales de eliminar variables del modelo?\n",
    "\n",
    "Eliminar variables reduce la complejidad del modelo, acelera el tiempo de entrenamiento y disminuye el riesgo de sobreajuste. Tambi√©n permite un uso m√°s eficiente de recursos computacionales, lo cual es importante si el modelo se implementa en producci√≥n o en dispositivos con capacidad limitada. Adem√°s, mejora la interpretabilidad del modelo.\n",
    "\n",
    "- ¬øEl modelo con menor dimensionalidad es m√°s sencillo de explicar?\n",
    "\n",
    "S√≠. Un modelo con menos variables es m√°s f√°cil de entender, visualizar y justificar ante personas no t√©cnicas. Al reducir el n√∫mero de caracter√≠sticas, se puede identificar m√°s claramente qu√© factores son clave en la toma de decisiones del modelo, lo que facilita su explicaci√≥n y validaci√≥n por parte de expertos del dominio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTG5cH9r3M9g"
   },
   "source": [
    "### 2.3 Calibraci√≥n Probabilistica [6 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDL0VqjR7yvb"
   },
   "source": [
    "<center>\n",
    "<img src='https://media2.giphy.com/media/l2Je4Ku0Cx292KWv6/200w.gif?cid=6c09b952y0sihtq9tb6sz8j2023x3zxxp3qx1ocgonkpkblj&ep=v1_gifs_search&rid=200w.gif&ct=g' width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmOKxhAw3sic"
   },
   "source": [
    "Para lograr modelos m√°s modulares, se recomienda realizar una calibraci√≥n del modelo entrenado anteriormente, con el objetivo de obtener salidas que reflejen mayor modularidad.\n",
    "\n",
    "1. Se solicita que utilice un m√©todo de calibraci√≥n que asegure que las probabilidades generadas incrementen de manera mon√≥tona. Una m√©trica ampliamente utilizada para evaluar la precisi√≥n de la calibraci√≥n de un modelo es el Brier Score. Calcule el Brier Score para el modelo tanto antes como despu√©s de la calibraci√≥n. Esto le permitir√° realizar una comparaci√≥n cuantitativa y determinar si la calibraci√≥n ha mejorado el rendimiento del modelo. Para m√°s informaci√≥n sobre el Brier Score, puede consultar el siguiente enlace: [Scikit-Learn - Brier Score Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html). [3 puntos]\n",
    "\n",
    "2. Tras la calibraci√≥n, examine y comente los resultados obtenidos. A su an√°lisis a√±ada una comparaci√≥n visual de las ideales versus las salidas del modelo original (sin calibrar) y del modelo calibrado. [3 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIiYz_qLuD19"
   },
   "source": [
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0bfSuiFuD2I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mucho √©xito!\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.pinimg.com/originals/55/3d/42/553d42bea9b10e0662a05aa8726fc7f4.gif\" width=300>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "k-ao0mOU64Ru",
    "Jg_9jBqtgRDO",
    "JdcucZhp-M_0",
    "Qfre1YsSDqla",
    "Bv1HOfcNEPF4",
    "poc9HSNBFeKO",
    "uy5VMU6ae_g6",
    "9bL2m8nNojXM",
    "rD8pQ5Zfq8dE",
    "K8DSS3u1xMpB",
    "PTG5cH9r3M9g"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
