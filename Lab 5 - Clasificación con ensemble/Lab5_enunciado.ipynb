{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Tgm8mCA9Dp3"
   },
   "source": [
    "# Laboratorio 5: Clasificación 🤗\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos - Primavera 2024</strong></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11Kc_ibM9GXH"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesores: Stefano Schiappacasse, Sebastián Tinoco\n",
    "- Auxiliares: Melanie Peña, Valentina Rojas\n",
    "- Ayudantes: Angelo Muñoz, Valentina Zúñiga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9dUSltr9JrN"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
    "\n",
    "- Nombre de alumno 1: *Diego Espinoza Núñez*\n",
    "- Nombre de alumno 2: *Juan Miño*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC1IloytrsAx"
   },
   "source": [
    "### **Link de repositorio de GitHub:** [juansebm/MDS7202](https://github.com/juansebm/MDS7202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBa48PDF9OHw"
   },
   "source": [
    "### Temas a tratar\n",
    "- Clasificación en problemas desbalanceados\n",
    "- Lightgbm y xgboost\n",
    "- Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkhnnMx49Qrh"
   },
   "source": [
    "## Reglas:\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Fecha de entrega: 6 días de plazo con descuento de 1 punto por día. Entregas Martes a las 23:59.\n",
    "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
    "- <u>Prohibidas las copias</u>. Cualquier intento de copia será debidamente penalizado con el reglamento de la escuela.\n",
    "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no estén en u-cursos no serán revisados. Recuerden que el repositorio también tiene nota.\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
    "- Pueden usar cualquier material del curso que estimen conveniente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxzJ48Vv8quO"
   },
   "source": [
    "\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "- Comprender cómo trabajar con problemas de clasificación con clases desbalanceadas.\n",
    "- Aplicar los modelos lightgbm y xgboost.\n",
    "- Practicar Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-ao0mOU64Ru"
   },
   "source": [
    "# Parte Teórica [12 puntos]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApXKwPDmxcEV"
   },
   "source": [
    "1. Explique cuál es la diferencia entre los datos de entrenamiento y validación. [1 punto]\n",
    "\n",
    "2. Explique cuál es el principal desafío al trabajar problemas de clasificación con data no supervisada. [1 punto]\n",
    "\n",
    "3. Explique en **sus palabras** qué es la matriz de confusión y para qué se utiliza. [1 puntos]\n",
    "\n",
    "4. Escriba la fórmula de las siguientes métricas y explique con **sus palabras** cómo se interpretan. [1 punto cada uno]\n",
    "\n",
    "  * Accuracy\n",
    "  * Precision\n",
    "  * Recall\n",
    "  * F1 score\n",
    "\n",
    "5. Explique qué métrica recomendaría para los siguientes contextos de clasificación. [1 punto cada uno]\n",
    "\n",
    "  * Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \n",
    "  * Detección de enfermedades altamente contagiosas.\n",
    "  * Aprobación de créditos de alto riesgo.\n",
    "  * Detección de crímenes.\n",
    "\n",
    "6. Explique qué es la calibración de modelos y para qué se usa. [1 punto]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy4QMWD8-FPk"
   },
   "source": [
    "**Respuesta:**\n",
    "\n",
    "1. **Entrenamiento se usa para entrenar el modelo. Validación se utiliza para seleccionar el mejor modelo a medida que se alteran los hiperparámetros.**\n",
    "2.\n",
    "3.\n",
    "4.\n",
    "5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYFdD1aK-ICa"
   },
   "source": [
    "*Escriba su respuesta aquí*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg_9jBqtgRDO"
   },
   "source": [
    "# Parte práctica [48 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slm6yRfdfZwS"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1BnO4tyh3vM2P199Ec9s3JjngQ4qQ9seP\"\n",
    "\" width=\"300\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Tras el trágico despido de la mítica mascota de Maipú, Renacín decide adentrarse como consultor en el mercado futbolero, el cuál (para variar...) está cargado en especulaciones.\n",
    "\n",
    "Como su principal tarea será asesorar a los directivos de los clubes sobre cuál jugador comprar y cuál no, Renacín desea generar modelos predictivos que evaluén distintas características de los jugadores; todo con el fin de tomar decisiones concretas basadas en los datos.\n",
    "\n",
    "Sin embargo, su condición de corporeo le impidió tomar la versión anterior de MDS7202, por lo que este motivo Renacín contrata a su equipo para lograr su objetivo final. Dado que aún tiene fuertes vínculos con la dirección de deportes de la municipalidad, el corporeo le entrega base de datos con las estadísticas de cada jugador para que su equipo empieze a trabajar ya con un dataset listo para ser usado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnbx7RwHfkue"
   },
   "source": [
    "**Los Datos**\n",
    "\n",
    "Para este laboratorio deberán trabajar con el csv `statsplayers.csv`, donde deberán aplicar algoritmos de aprendizaje supervisado de clasificación en base a características que describen de jugadores de fútbol.\n",
    "\n",
    "Para comenzar cargue el dataset señalado y a continuación vea el reporte **`Player_Stats_Report.html`** (adjunto en la carpeta del enunciado) que describe las características principales del `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mX6iwOWUfrp_"
   },
   "outputs": [],
   "source": [
    "# Si usted está utilizando Colabolatory le puede ser útil este código para cargar los archivos.\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    path = 'Dirección donde tiene los archivos en el Drive'\n",
    "except:\n",
    "    print('Ignorando conexión drive-colab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdcucZhp-M_0"
   },
   "source": [
    "## 1. Predicción de Seleccionados Nacionales [14 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXrewqxjjzvA"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://www.futuro.cl/wp-content/uploads/2016/06/chile-argentina-meme-12.jpg\" width=\"300\">\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qfre1YsSDqla"
   },
   "source": [
    "### 1.1 Preprocesamiento [5 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR00u4HTDtxv"
   },
   "source": [
    "Tareas:\n",
    "\n",
    "1. Genere los labels para la clasificación binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su país. [Sin puntaje]\n",
    "\n",
    "2. Hecho esto, ¿cuántos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]\n",
    "\n",
    "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y guárdelo una variable llamada `col_transformer`. [2 puntos]\n",
    "\n",
    "4. Comente y justifique las transformaciones elegidas sobre cada una de las variables (para esto utilice el material `Player_Stats_Report.html` que viene en el zip del lab), al igual que las transformaciones aplicadas. [2 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgAk0kbPjEsx"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhC2sZj9dSI1"
   },
   "outputs": [],
   "source": [
    "# 1. Cargar y preparar los datos\n",
    "df = pd.read_csv('statsplayers.csv')\n",
    "\n",
    "# Definir grupos de posiciones (excluyendo arquero)\n",
    "position_groups = {\n",
    "    'ataque': ['ST', 'CF'],\n",
    "    'central_ataque': ['RW', 'CAM', 'LW'],\n",
    "    'central': ['RM', 'CM', 'LM'],\n",
    "    'central_defensa': ['RWB', 'CDM', 'LWB'],\n",
    "    'defensa': ['RB', 'CB', 'LB']\n",
    "}\n",
    "\n",
    "# Filtrar posiciones válidas\n",
    "valid_positions = [pos for group in position_groups.values() for pos in group]\n",
    "df_filtered = df[df['Club_Position'].isin(valid_positions)].copy()\n",
    "\n",
    "# Crear labels\n",
    "df_filtered['label'] = df_filtered['Club_Position'].apply(\n",
    "    lambda x: next((k for k, v in position_groups.items() if x in v), None)\n",
    ")\n",
    "df_filtered = df_filtered.dropna(subset=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bv1HOfcNEPF4"
   },
   "source": [
    "### 1.2 Entrenamiento [3 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPkuXTUBvB0"
   },
   "source": [
    "Ahora, vamos a entrenar los pipelines generados en los pasos anteriores. Para esto, debe realizar las siguientes tareas:\n",
    "\n",
    "1. Separe los datos de entrenamiento en un conjunto de entrenamiento y de prueba  (la proporción queda a su juicio). En este paso, seleccione los ejemplos de forma aleatoria e intente mantener la distribución original de labels de cada clase en los conjuntos de prueba/entrenamiento. (vea la documentación de `train_test_split`). [1 puntos]\n",
    "\n",
    "\n",
    "2. Defina un pipeline llamado `pipeline_xgboost` y otro llamado `pipeline_lightgbm`. Estos pipelines deben tener el mismo ColumnTransformer definido en la sección de preprocesamiento, pero deben variar los clasificadores de acuerdo al nombre de cada pipeline. [1 puntos]\n",
    "\n",
    "3. Entrene los pipelines. [1 punto]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbadONFtjGnE"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLtlXGTPdWAV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poc9HSNBFeKO"
   },
   "source": [
    "### 1.3 Resultados [6 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGGCj8YtFil1"
   },
   "source": [
    "1. Calcule las métricas accuracy, precisión y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
    "\n",
    "2. Explique qué implican los valores de accuracy, precisión y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y cómo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
    "\n",
    "3. Explique qué métrica le parece más adecuada y concluya qué modelo tiene un mejor desempeño. [2 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1hkVFdujJTi"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNmI_tbbdQte"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy5VMU6ae_g6"
   },
   "source": [
    "## 2. Predicción de posiciones de jugadores [4 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0PGg_hLgr4H"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://pbs.twimg.com/media/E1rfA1aWEAYU6Ny.jpg\" width=\"300\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6rSnAesfOm3"
   },
   "source": [
    "En una nueva jornada de desmesuradas transacciones deportivas, Renacín escuchó a sus colegas discutir acerca de que el precio de cada jugador depende en gran medida de la posición en la cancha en la que juega. Y además, que hay bastantes jugadores nuevos que no tienen muy claro en que posición verdaderamente brillarían, por lo que actualmente puede que actualmente estén jugando en posiciones sub-optimas.\n",
    "\n",
    "Viendo que los resultados del primer análisis no son tan esperanzadores, el corporeo los comanda a cambiar su tarea: ahora, les solicita que construyan un clasificador enfocado en predecir la mejor posición de los jugadores en la cancha según sus características.\n",
    "\n",
    "Para lograr esto, primero, les pide que etiqueten de la siguiente manera los valores que aparecen en el atributo `Club_Position`, pidiendo que agrupen los valores en los siguientes grupos:\n",
    "\n",
    "**Nota**:  Renacín les recalca que **no deben utilizar los valores ```Sub``` y ```Res``` de esta columna**.\n",
    "\n",
    "```python\n",
    "ataque = ['ST', 'CF']\n",
    "central_ataque = ['RW', 'CAM', 'LW']\n",
    "central = ['RM', 'CM', 'LM']\n",
    "central_defensa = ['RWB', 'CDM', 'LWB']\n",
    "defensa = ['RB', 'CB', 'LB']\n",
    "arquero = ['GK']\n",
    "```\n",
    "\n",
    "La elección del clasificador se justificar en base a la siguiente [guía](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) y se deben comentar los resultados obtenidos en la clasificación.\n",
    "\n",
    "**Tareas:** [1 punto por tarea]\n",
    "\n",
    "1. En un nuevo dataframe, aplique las etiquetas descritas anteriormente en cada uno de los valores señalados en esta sección y guárdelos en la variable `label`.\n",
    "2. Cuente cuántos por clase quedan.\n",
    "3. Entrene el nuevo pipeline y ejecute una evaluación de este.  \n",
    "4. Comente los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBmSaWh8i2MI"
   },
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ir_7zMh2i1vg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bL2m8nNojXM"
   },
   "source": [
    "## 3. Predicciones de Seleccionados Nacionales para el Jere Klein [30 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2XmRsJdsEh_"
   },
   "source": [
    "<center>\n",
    "<img src='https://www.radioactiva.cl/wp-content/uploads/2024/04/Jere-Klein-1-768x432.webp' width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgmUoVDsqUPu"
   },
   "source": [
    "Después de alcanzar la fama como cantante urbano, Jere Klein decide explorar una nueva faceta. Con su amor por el fútbol y convencido de que los artistas urbanos poseen un talento y versatilidad excepcionales, Jere se embarca en un proyecto innovador: desarrollar un sistema de inteligencia artificial capaz de identificar a jugadores que tienen potencial para convertirse en futbolistas profesionales. Su teoría es que muchos artistas del género urbano chileno, con sus habilidades únicas y su disciplina, podrían destacarse también en el deporte. Con este sistema, Jere espera no solo abrir nuevas oportunidades para sus colegas artistas, sino también demostrar la amplia gama de talentos que pueden ofrecer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD8pQ5Zfq8dE"
   },
   "source": [
    "### 2.1 ¿Qué modelo de árbol es más de \"pana\"? [10 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zB-KUA4g99eo"
   },
   "source": [
    "<center>\n",
    "<img src='https://64.media.tumblr.com/39189215a7d3d96823cb359f35b44e05/tumblr_psmrhrR3Xw1qf5hjqo4_540.gif' width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uL-moVhB9vPH"
   },
   "source": [
    "\n",
    "**Tareas**\n",
    "\n",
    "\n",
    "1. Considerando el la variable llamada `label` creada en la sección 1.1. Para determinar cuál modelo de árbol sería más adecuado para la tarea en cuestión, utilice PyCaret. Este deberá centrarse exclusivamente en modelos de tipo árbol. Jere ha especificado que busca un modelo que tome decisiones rápidamente y que tenga una baja tasa de falsos positivos, ya que planea invertir en estos jugadores. [3 puntos]\n",
    "\n",
    "Para la comparación, utilice los siguientes modelos:\n",
    "\n",
    "```python\n",
    "['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
    "```\n",
    "\n",
    "2. Explique en brevemente que son los modelos de la siguiente lista `['et', 'rf', 'dt']` y como funcionan. [3 punto]\n",
    "\n",
    "3. Tras realizar la comparación de modelos, seleccione aquel que muestre el mejor rendimiento en términos de velocidad y precisión, especialmente en la reducción de falsos positivos. Utilice la función `evaluate_model` de PyCaret para revisar y analizar los resultados obtenidos en los siguientes aspectos:\n",
    "\n",
    "  - **Confusión Matrix**: ¿Cómo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
    "  - **Threshold**: ¿Es acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
    "  - **Feature Importance**: ¿Cuáles son las variables con mejor desempeño? ¿A qué podría deberse esto?\n",
    "  - **Learning Curve**: ¿El modelo presenta algún problema?\n",
    "\n",
    "  [4 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qY85nrViYROF"
   },
   "source": [
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Cargar y preparar datos (basado en tu código)\n",
    "df = pd.read_csv('stats_players.csv')\n",
    "\n",
    "# Definir grupos de posiciones\n",
    "position_groups = {\n",
    "    'ataque': ['ST', 'CF'],\n",
    "    'central_ataque': ['RW', 'CAM', 'LW'],\n",
    "    'central': ['RM', 'CM', 'LM'],\n",
    "    'central_defensa': ['RWB', 'CDM', 'LWB'],\n",
    "    'defensa': ['RB', 'CB', 'LB']\n",
    "}\n",
    "\n",
    "# Filtrar posiciones válidas\n",
    "valid_positions = [pos for group in position_groups.values() for pos in group]\n",
    "df = df[df['Club_Position'].isin(valid_positions)].copy()\n",
    "\n",
    "# Crear variable label\n",
    "df['label'] = df['Club_Position'].apply(\n",
    "    lambda x: next((k for k, v in position_groups.items() if x in v), None)\n",
    ")\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# Preparar datos para PyCaret\n",
    "data = df.drop('Club_Position', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUCjOjsEYUXL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ad764 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ad764_row0_col0, #T_ad764_row0_col4, #T_ad764_row1_col0, #T_ad764_row1_col1, #T_ad764_row1_col2, #T_ad764_row1_col3, #T_ad764_row1_col5, #T_ad764_row1_col6, #T_ad764_row1_col7, #T_ad764_row2_col0, #T_ad764_row2_col1, #T_ad764_row2_col2, #T_ad764_row2_col3, #T_ad764_row2_col4, #T_ad764_row2_col5, #T_ad764_row2_col6, #T_ad764_row2_col7, #T_ad764_row3_col0, #T_ad764_row3_col1, #T_ad764_row3_col2, #T_ad764_row3_col3, #T_ad764_row3_col4, #T_ad764_row3_col5, #T_ad764_row3_col6, #T_ad764_row3_col7, #T_ad764_row4_col0, #T_ad764_row4_col1, #T_ad764_row4_col2, #T_ad764_row4_col3, #T_ad764_row4_col4, #T_ad764_row4_col5, #T_ad764_row4_col6, #T_ad764_row4_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ad764_row0_col1, #T_ad764_row0_col2, #T_ad764_row0_col3, #T_ad764_row0_col5, #T_ad764_row0_col6, #T_ad764_row0_col7, #T_ad764_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_ad764_row0_col8, #T_ad764_row1_col8, #T_ad764_row2_col8, #T_ad764_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_ad764_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ad764\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ad764_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_ad764_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_ad764_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_ad764_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_ad764_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_ad764_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_ad764_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_ad764_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_ad764_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ad764_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_ad764_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_ad764_row0_col1\" class=\"data row0 col1\" >0.3232</td>\n",
       "      <td id=\"T_ad764_row0_col2\" class=\"data row0 col2\" >0.8251</td>\n",
       "      <td id=\"T_ad764_row0_col3\" class=\"data row0 col3\" >0.3232</td>\n",
       "      <td id=\"T_ad764_row0_col4\" class=\"data row0 col4\" >0.4799</td>\n",
       "      <td id=\"T_ad764_row0_col5\" class=\"data row0 col5\" >0.2659</td>\n",
       "      <td id=\"T_ad764_row0_col6\" class=\"data row0 col6\" >0.1745</td>\n",
       "      <td id=\"T_ad764_row0_col7\" class=\"data row0 col7\" >0.2249</td>\n",
       "      <td id=\"T_ad764_row0_col8\" class=\"data row0 col8\" >1.3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad764_level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n",
       "      <td id=\"T_ad764_row1_col0\" class=\"data row1 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_ad764_row1_col1\" class=\"data row1 col1\" >0.2433</td>\n",
       "      <td id=\"T_ad764_row1_col2\" class=\"data row1 col2\" >0.7545</td>\n",
       "      <td id=\"T_ad764_row1_col3\" class=\"data row1 col3\" >0.2433</td>\n",
       "      <td id=\"T_ad764_row1_col4\" class=\"data row1 col4\" >0.5051</td>\n",
       "      <td id=\"T_ad764_row1_col5\" class=\"data row1 col5\" >0.1422</td>\n",
       "      <td id=\"T_ad764_row1_col6\" class=\"data row1 col6\" >0.1166</td>\n",
       "      <td id=\"T_ad764_row1_col7\" class=\"data row1 col7\" >0.1580</td>\n",
       "      <td id=\"T_ad764_row1_col8\" class=\"data row1 col8\" >0.7240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad764_level0_row2\" class=\"row_heading level0 row2\" >dt</th>\n",
       "      <td id=\"T_ad764_row2_col0\" class=\"data row2 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_ad764_row2_col1\" class=\"data row2 col1\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row2_col2\" class=\"data row2 col2\" >0.5005</td>\n",
       "      <td id=\"T_ad764_row2_col3\" class=\"data row2 col3\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row2_col4\" class=\"data row2 col4\" >0.1746</td>\n",
       "      <td id=\"T_ad764_row2_col5\" class=\"data row2 col5\" >0.0544</td>\n",
       "      <td id=\"T_ad764_row2_col6\" class=\"data row2 col6\" >0.0009</td>\n",
       "      <td id=\"T_ad764_row2_col7\" class=\"data row2 col7\" >0.0125</td>\n",
       "      <td id=\"T_ad764_row2_col8\" class=\"data row2 col8\" >0.8840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad764_level0_row3\" class=\"row_heading level0 row3\" >xgboost</th>\n",
       "      <td id=\"T_ad764_row3_col0\" class=\"data row3 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_ad764_row3_col1\" class=\"data row3 col1\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row3_col2\" class=\"data row3 col2\" >0.7172</td>\n",
       "      <td id=\"T_ad764_row3_col3\" class=\"data row3 col3\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row3_col4\" class=\"data row3 col4\" >0.1746</td>\n",
       "      <td id=\"T_ad764_row3_col5\" class=\"data row3 col5\" >0.0544</td>\n",
       "      <td id=\"T_ad764_row3_col6\" class=\"data row3 col6\" >0.0009</td>\n",
       "      <td id=\"T_ad764_row3_col7\" class=\"data row3 col7\" >0.0125</td>\n",
       "      <td id=\"T_ad764_row3_col8\" class=\"data row3 col8\" >0.9440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad764_level0_row4\" class=\"row_heading level0 row4\" >lightgbm</th>\n",
       "      <td id=\"T_ad764_row4_col0\" class=\"data row4 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_ad764_row4_col1\" class=\"data row4 col1\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row4_col2\" class=\"data row4 col2\" >0.6665</td>\n",
       "      <td id=\"T_ad764_row4_col3\" class=\"data row4 col3\" >0.1763</td>\n",
       "      <td id=\"T_ad764_row4_col4\" class=\"data row4 col4\" >0.1746</td>\n",
       "      <td id=\"T_ad764_row4_col5\" class=\"data row4 col5\" >0.0544</td>\n",
       "      <td id=\"T_ad764_row4_col6\" class=\"data row4 col6\" >0.0009</td>\n",
       "      <td id=\"T_ad764_row4_col7\" class=\"data row4 col7\" >0.0125</td>\n",
       "      <td id=\"T_ad764_row4_col8\" class=\"data row4 col8\" >0.4640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2409246ec10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.datasets import get_data\n",
    "from pycaret.classification import *\n",
    "import os\n",
    "\n",
    "os.environ[\"PYCARET_CUSTOM_LOGGING_LEVEL\"] = \"CRITICAL\"\n",
    "\n",
    "\n",
    "# Configurar el entorno de PyCaret\n",
    "clf = setup(\n",
    "    data=data,  # ✅ Aquí estás usando el df limpio sin Club_Position\n",
    "    target='label',\n",
    "    session_id=123, \n",
    "    fold_strategy='kfold',\n",
    "    fold=5,\n",
    "    verbose=False, \n",
    "    use_gpu=False,  # ⚠️ pon False si no estás en Colab con GPU de NVIDIA\n",
    "    log_experiment=False\n",
    ")\n",
    "\n",
    "# Modelos a comparar (solo modelos de árboles)\n",
    "modelos_arbol = ['et', 'rf', 'dt', 'xgboost', 'lightgbm'] # catboost NO DISPONIBLE!\n",
    "\n",
    "# Comparar modelos\n",
    "best_model = compare_models(include=modelos_arbol, sort='F1')  # Buscamos balance entre precision y recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3307, 40)\n",
      "label\n",
      "defensa            1180\n",
      "central             907\n",
      "central_ataque      581\n",
      "ataque              430\n",
      "central_defensa     209\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_filtered.shape)\n",
    "print(df_filtered['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decision Tree (Árbol de Decisión):*\n",
    "Es un modelo que clasifica datos dividiéndolos de forma jerárquica mediante condiciones como \"¿X > umbral?\". Utiliza métricas como Gini o Entropía para elegir las divisiones. Es fácil de interpretar, pero puede sobreajustarse si no se limita su profundidad.\n",
    "\n",
    "*Random Forest:*\n",
    "Consiste en múltiples árboles de decisión entrenados sobre subconjuntos aleatorios de los datos y características. Combina sus predicciones por votación mayoritaria, lo que reduce el sobreajuste y mejora la precisión.\n",
    "\n",
    "*Extra Trees:*\n",
    "Es similar a Random Forest, pero introduce aún más aleatoriedad al seleccionar divisiones de forma aleatoria en vez de óptima. Esto permite entrenamientos más rápidos y, en algunos casos, mejor generalización, aunque con posible pérdida leve de precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*El mejor modelo fue Extra Trees Classifier, ya que obtuvo los valores más altos en todas las métricas clave: Accuracy (0.3232), AUC (0.8251), Recall (0.3232), y especialmente F1 Score (0.2659), lo que indica un buen balance entre precisión y sensibilidad. Además, su MCC de 0.2249 y Kappa de 0.1745 superan ampliamente al resto, lo que confirma que logra una mejor discriminación entre clases. Aunque su tiempo de entrenamiento fue más alto, el desempeño global justifica su elección como el modelo más robusto para esta tarea.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8DSS3u1xMpB"
   },
   "source": [
    "### 2.2 Reducción de dimensionalidad [14 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLu0543p876P"
   },
   "source": [
    "<center>\n",
    "<img src='https://i.kym-cdn.com/photos/images/original/002/258/560/668.gif' width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT-bxJ0txwNF"
   },
   "source": [
    "A pesar de los resultados obtenidos previamente, el manager de Jere ha solicitado el entrenamiento de un modelo de XGBoost utilizando los datos disponibles. Además, se debe proceder a realizar una reducción de dimensionalidad basada en la importancia de las características.\n",
    "\n",
    "Para llevar a cabo esta tarea:\n",
    "\n",
    "1. Inicie entrenando un modelo XGBoost con todas las características disponibles. [2 puntos]\n",
    "\n",
    "2. Una vez el modelo esté entrenado, evalúe y clasifique las características según su importancia de forma descendente. [2 puntos]\n",
    "\n",
    "3. Utilice esta clasificación para ejecutar una búsqueda recursiva de eliminación de características, eliminando progresivamente las menos importantes y evaluando el impacto en el desempeño del modelo hasta identificar las N características más críticas. [2 puntos]\n",
    "\n",
    "4. Con este conjunto reducido de características, entrene un nuevo modelo y evalúe su rendimiento. [2 puntos]\n",
    "\n",
    "5. Posteriormente, responda a las siguientes preguntas para una comprensión más profunda de los cambios y beneficios:\n",
    "\n",
    "  - ¿El rendimiento del modelo con las características seleccionadas es similar al del modelo original? ¿Cómo se comparan en términos de precisión y robustez? [2 puntos]\n",
    "  - ¿Cuáles son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificación del modelo, reducción del tiempo de entrenamiento, y mejora en la capacidad de generalización. [2 puntos]\n",
    "  - Comente si el modelo con menor dimensionalidad es más sencillo de explicar. Explique brevemente por qué la eliminación de ciertas características puede facilitar la comprensión y la explicación del comportamiento del modelo. [2 puntos]\n",
    "\n",
    "Notar que con esta metodologia buscamos encontrar un punto entermedio entre número de festures y desempeño. por esto, si observa que al aumentar festires el aumento es despreciable, puede no considerar agregar más features a su modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHfmK63TuDOS"
   },
   "source": [
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "HQwUd_nsuDOe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo original:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86        86\n",
      "           1       0.58      0.64      0.61       182\n",
      "           2       0.48      0.38      0.42       116\n",
      "           3       0.63      0.29      0.39        42\n",
      "           4       0.85      0.94      0.89       236\n",
      "\n",
      "    accuracy                           0.71       662\n",
      "   macro avg       0.67      0.62      0.63       662\n",
      "weighted avg       0.69      0.71      0.70       662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"stats_players.csv\")\n",
    "\n",
    "# Definir grupos de posiciones\n",
    "position_groups = {\n",
    "    'ataque': ['ST', 'CF'],\n",
    "    'central_ataque': ['RW', 'CAM', 'LW'],\n",
    "    'central': ['RM', 'CM', 'LM'],\n",
    "    'central_defensa': ['RWB', 'CDM', 'LWB'],\n",
    "    'defensa': ['RB', 'CB', 'LB']\n",
    "}\n",
    "\n",
    "# Filtrar solo posiciones válidas\n",
    "valid_positions = [pos for v in position_groups.values() for pos in v]\n",
    "df = df[df['Club_Position'].isin(valid_positions)].copy()\n",
    "\n",
    "# Crear etiquetas\n",
    "df['label'] = df['Club_Position'].apply(lambda x: next(k for k, v in position_groups.items() if x in v))\n",
    "\n",
    "# Codificar etiquetas a números\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['label'])\n",
    "\n",
    "# Eliminar columnas irrelevantes de texto\n",
    "drop_cols = ['Club_Position', 'label', 'Name', 'Nationality', 'National_Position', 'Preffered_Foot', 'Work_Rate', 'Body_Type', 'Real_Face', 'Position', 'Joined', 'Loaned_From', 'Contract_Valid_Until', 'Best_Position']\n",
    "X = df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Convertir posibles columnas categóricas restantes en numéricas (si queda alguna)\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# Split en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo\n",
    "model_full = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "model_full.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar desempeño\n",
    "y_pred_full = model_full.predict(X_test)\n",
    "print(\"Modelo original:\\n\", classification_report(y_test, y_pred_full))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            feature  importance\n",
      "8    Sliding_Tackle    0.224784\n",
      "27        Finishing    0.060838\n",
      "7           Marking    0.059455\n",
      "25          Heading    0.047663\n",
      "15         Crossing    0.045030\n",
      "13           Vision    0.043964\n",
      "9   Standing_Tackle    0.030099\n",
      "16       Short_Pass    0.027484\n",
      "17        Long_Pass    0.026890\n",
      "19            Speed    0.026389\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model_full.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(feature_importance.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 features → F1 Score: 0.6223\n",
      "10 features → F1 Score: 0.6984\n",
      "15 features → F1 Score: 0.6829\n",
      "20 features → F1 Score: 0.6997\n",
      "25 features → F1 Score: 0.6684\n",
      "30 features → F1 Score: 0.6857\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for n in range(5, len(feature_importance)+1, 5):\n",
    "    top_features = feature_importance['feature'].iloc[:n].tolist()\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "    model.fit(X_train[top_features], y_train)\n",
    "    preds = model.predict(X_test[top_features])\n",
    "    score = f1_score(y_test, preds, average='weighted')\n",
    "    scores.append((n, score))\n",
    "\n",
    "# Mostrar resultados\n",
    "for n, score in scores:\n",
    "    print(f\"{n} features → F1 Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo reducido:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        86\n",
      "           1       0.61      0.64      0.63       182\n",
      "           2       0.47      0.40      0.43       116\n",
      "           3       0.71      0.24      0.36        42\n",
      "           4       0.84      0.95      0.89       236\n",
      "\n",
      "    accuracy                           0.72       662\n",
      "   macro avg       0.69      0.63      0.63       662\n",
      "weighted avg       0.70      0.72      0.70       662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_n = 20\n",
    "selected_features = feature_importance['feature'].iloc[:top_n].tolist()\n",
    "\n",
    "model_reduced = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "model_reduced.fit(X_train[selected_features], y_train)\n",
    "\n",
    "y_pred_reduced = model_reduced.predict(X_test[selected_features])\n",
    "print(\"Modelo reducido:\\n\", classification_report(y_test, y_pred_reduced))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿El rendimiento del modelo con las características seleccionadas es similar al del modelo original?\n",
    "\n",
    "Sí, el rendimiento del modelo reducido fue comparable al modelo original. La métrica F1 Score se mantuvo estable con solo 20 características, lo que sugiere que las variables eliminadas aportaban poca información adicional. La precisión y robustez del modelo se mantuvieron sin comprometer su capacidad predictiva.\n",
    "\n",
    "- ¿Cuáles son los beneficios potenciales de eliminar variables del modelo?\n",
    "\n",
    "Eliminar variables reduce la complejidad del modelo, acelera el tiempo de entrenamiento y disminuye el riesgo de sobreajuste. También permite un uso más eficiente de recursos computacionales, lo cual es importante si el modelo se implementa en producción o en dispositivos con capacidad limitada. Además, mejora la interpretabilidad del modelo.\n",
    "\n",
    "- ¿El modelo con menor dimensionalidad es más sencillo de explicar?\n",
    "\n",
    "Sí. Un modelo con menos variables es más fácil de entender, visualizar y justificar ante personas no técnicas. Al reducir el número de características, se puede identificar más claramente qué factores son clave en la toma de decisiones del modelo, lo que facilita su explicación y validación por parte de expertos del dominio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTG5cH9r3M9g"
   },
   "source": [
    "### 2.3 Calibración Probabilistica [6 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDL0VqjR7yvb"
   },
   "source": [
    "<center>\n",
    "<img src='https://media2.giphy.com/media/l2Je4Ku0Cx292KWv6/200w.gif?cid=6c09b952y0sihtq9tb6sz8j2023x3zxxp3qx1ocgonkpkblj&ep=v1_gifs_search&rid=200w.gif&ct=g' width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmOKxhAw3sic"
   },
   "source": [
    "Para lograr modelos más modulares, se recomienda realizar una calibración del modelo entrenado anteriormente, con el objetivo de obtener salidas que reflejen mayor modularidad.\n",
    "\n",
    "1. Se solicita que utilice un método de calibración que asegure que las probabilidades generadas incrementen de manera monótona. Una métrica ampliamente utilizada para evaluar la precisión de la calibración de un modelo es el Brier Score. Calcule el Brier Score para el modelo tanto antes como después de la calibración. Esto le permitirá realizar una comparación cuantitativa y determinar si la calibración ha mejorado el rendimiento del modelo. Para más información sobre el Brier Score, puede consultar el siguiente enlace: [Scikit-Learn - Brier Score Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html). [3 puntos]\n",
    "\n",
    "2. Tras la calibración, examine y comente los resultados obtenidos. A su análisis añada una comparación visual de las ideales versus las salidas del modelo original (sin calibrar) y del modelo calibrado. [3 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIiYz_qLuD19"
   },
   "source": [
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0bfSuiFuD2I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mucho éxito!\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.pinimg.com/originals/55/3d/42/553d42bea9b10e0662a05aa8726fc7f4.gif\" width=300>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "k-ao0mOU64Ru",
    "Jg_9jBqtgRDO",
    "JdcucZhp-M_0",
    "Qfre1YsSDqla",
    "Bv1HOfcNEPF4",
    "poc9HSNBFeKO",
    "uy5VMU6ae_g6",
    "9bL2m8nNojXM",
    "rD8pQ5Zfq8dE",
    "K8DSS3u1xMpB",
    "PTG5cH9r3M9g"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
